{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Guess Core and use other methods to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "from scf_guess_tools import  Backend, load, calculate, guess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from BlockMatrix import BlockMatrix\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "\n",
    "#! Only if there are no cudo CPUs in the system!\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### 1b) Try on other dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from glob import glob\n",
    "sys.path.append(\"..\")\n",
    "from utils import  plot_mat_comp, flatten_triang_batch, flatten_triang, get_overlap, load_mol, unflatten_triang, density_from_fock, perform_calculation\n",
    "scripts_path = \"../../scripts\"\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "from to_cache import density_fock_overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_seed = 42\n",
    "source_path = '../../datasets/QM9/xyz_c7h10o2/'\n",
    "all_file_paths = glob(os.path.join(source_path, '*.xyz'))\n",
    "n_elec = 19\n",
    "len(all_file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached(file_paths, cache_path, basis, guess=\"minao\", method=\"dft\", functional=\"b3lypg\", backend=\"pyscf\"):\n",
    "    error_list = []\n",
    "    error_files = []\n",
    "    focks = []\n",
    "    overlaps = []\n",
    "    used_files = []\n",
    "    reference_densities = []\n",
    "    for file in file_paths:\n",
    "        mol_name = os.path.basename(file).strip()\n",
    "        # print(mol_name)\n",
    "        try: \n",
    "            ret = density_fock_overlap(filepath = file,\n",
    "                                filename = mol_name,\n",
    "                                method = method,\n",
    "                                basis = None,\n",
    "                                functional = functional,\n",
    "                                guess = guess,\n",
    "                                backend = backend,\n",
    "                                cache = cache_path)\n",
    "            # print(f\"Using: file={file} - mol_name={mol_name} - basis={None} - guess={guess} - method={method} - functional={functional}\")\n",
    "        except Exception as e: \n",
    "            error_list.append(e)\n",
    "            error_files.append(mol_name)\n",
    "            print(f\"File {mol_name} error - skipping\")\n",
    "            continue\n",
    "        if any([r == None for r in ret]): \n",
    "            print(f\"File {mol_name} bad - skipping\")\n",
    "            continue\n",
    "        focks.append(ret[1].numpy)\n",
    "        used_files.append(file)\n",
    "        reference_densities.append(ret[0].numpy)\n",
    "        overlaps.append(ret[2].numpy)\n",
    "    print(f\"Got data for: {len(focks)} - bad / no ret: {len(file_paths) - len(focks) - len(error_list)} - errors: {len(error_list)}\")\n",
    "    print(error_files[:5])\n",
    "    return focks, reference_densities, overlaps, used_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = load_cached(all_file_paths, \"../../datasets/QM9/out/c7h10o2_b3lypg_6-31G(2df,p)/pyscf\", basis=\"6-31g_2df_p_custom_nwchem.gbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test_seed = 42\n",
    "all_data = [(fock, ref_density, overlap, file) for fock, ref_density, overlap, file in zip(*ret)]\n",
    "print(len(all_data))\n",
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=train_test_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_dim = train_data[0][0].shape\n",
    "mat_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_overlap_X = np.array([flatten_triang(data[2]) for data in train_data])\n",
    "# train_fock_Y = np.array([data[0] for data in train_data])\n",
    "train_fock_diag = np.array([np.diag(data[0]) for data in train_data])\n",
    "\n",
    "test_overlap_X = np.array([flatten_triang(data[2]) for data in test_data])\n",
    "# test_fock_Y = np.array([data[0] for data in test_data])\n",
    "test_fock_diag = np.array([np.diag(data[0]) for data in test_data])\n",
    "train_overlap_X.shape, test_overlap_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"data/train_overlap_X.pk\", \"wb\") as f:\n",
    "    pk.dump(train_overlap_X, f)\n",
    "with open(\"data/train_fock_diag.pk\", \"wb\") as f:\n",
    "    pk.dump(train_fock_diag, f)\n",
    "with open(\"data/test_overlap_X.pk\", \"wb\") as f:\n",
    "    pk.dump(test_overlap_X, f)\n",
    "with open(\"data/test_fock_diag.pk\", \"wb\") as f:\n",
    "    pk.dump(test_fock_diag, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pickle as pk\n",
    "with open(\"data/train_overlap_X.pk\", \"rb\") as f:\n",
    "    train_overlap_X = pk.load(f)\n",
    "with open(\"data/train_fock_diag.pk\", \"rb\") as f:\n",
    "    train_fock_diag = pk.load(f)\n",
    "with open(\"data/test_overlap_X.pk\", \"rb\") as f:\n",
    "    test_overlap_X = pk.load(f)\n",
    "with open(\"data/test_fock_diag.pk\", \"rb\") as f:\n",
    "    test_fock_diag = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_631g_basis = \"../../scripts/6-31g_2df_p_custom_nwchem.gbs\"\n",
    "example_mol_filepath = os.path.basename(train_data[0][3]).strip()\n",
    "example_mol = load_mol(train_data[0][3], custom_631g_basis, Backend.PY)\n",
    "example_ovlp = unflatten_triang(train_overlap_X[0], mat_dim[0])\n",
    "example_overlap = BlockMatrix(example_mol, example_ovlp)\n",
    "example_overlap.plot_blocks_by_type(\"all\", labels=\"atoms\", figsize=(10, 10), imshow_args={\"cmap\": \"RdBu\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "let's try our luck! - no rescaling for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "in_dim = train_overlap_X.shape[1]\n",
    "out_dim = train_fock_diag.shape[1]\n",
    "in_dim, out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "flattened_dim = train_overlap_X.shape[1]\n",
    "diag_dim = train_fock_diag.shape[1]\n",
    "inputs_orig = tf.keras.Input(shape=(flattened_dim,))\n",
    "x = inputs_orig\n",
    "for neurons in [1024,512,256]:\n",
    "    x = tf.keras.layers.Dense(neurons, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "outputs = tf.keras.layers.Dense(diag_dim)(x)\n",
    "\n",
    "basic_model = tf.keras.Model(inputs=inputs_orig, outputs=outputs)\n",
    "basic_model.compile(optimizer='adam', loss=\"mae\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\"models/basic_model_6_31G.h5\", save_best_only=True)\n",
    "basic_hist = basic_model.fit(train_overlap_X, train_fock_diag,\n",
    "                            validation_data=(test_overlap_X, test_fock_diag),\n",
    "                            epochs=100,\n",
    "                            batch_size=32,\n",
    "                            callbacks=[tensorboard_callback, checkpoint_callback],\n",
    "                            verbose=1)\n",
    "# Plot the training and validation loss\n",
    "plt.plot(basic_hist.history['loss'], label='train')\n",
    "plt.plot(basic_hist.history['val_loss'], label='validation')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mae')\n",
    "plt.title('Model loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "if os.path.exists(\"models/basic_model_6_31G.keras\") and input(\"Overwrite existing model? (y/n)\") == \"y\":\n",
    "    os.remove(\"models/basic_model_6_31G.keras\")\n",
    "    basic_model.save(\"models/basic_model_6_31G.keras\")\n",
    "    print(\"Model saved\")\n",
    "else:\n",
    "    basic_model.save(\"models/basic_model_6_31G.keras\")\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model = tf.keras.models.load_model(\"models/basic_model_6_31G.keras\")\n",
    "basic_model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_Fock(diag, ovlp, K = 1.75): \n",
    "    \"\"\"Take diagonal and reconstruct the Fock matrix using GWH\n",
    "    \"\"\"\n",
    "    mat_dim = diag.shape[0]\n",
    "    out = np.zeros((mat_dim, mat_dim))\n",
    "    for i in range(mat_dim):\n",
    "        for j in range(mat_dim):\n",
    "            if i == j:\n",
    "                out[i, j] = diag[i]\n",
    "            else:\n",
    "                out[i, j] = K * ovlp[i, j] * (diag[i] + diag[j]) / 2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict: \n",
    "test_pred_fock_diag = basic_model.predict(test_overlap_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example comparison: \n",
    "rand_test_sample = np.random.randint(0, len(test_pred_fock_diag))\n",
    "pred_fock_example = reconstruct_Fock(test_pred_fock_diag[rand_test_sample], unflatten_triang(test_overlap_X[rand_test_sample], mat_dim[0]))\n",
    "ground_truth_fock_example = test_data[rand_test_sample][0]\n",
    "pred_density_example = density_from_fock(pred_fock_example, unflatten_triang(test_overlap_X[rand_test_sample], mat_dim[0]), mat_dim[0])\n",
    "# compare with hückel and minao\n",
    "test_mol = load(test_data[rand_test_sample][3], symmetry=False, basis = custom_631g_basis, backend=Backend.PY)\n",
    "minao_guess = guess(test_mol, method=\"hf\", basis=custom_631g_basis, scheme=\"minao\")\n",
    "hueckel_guess = guess(test_mol, method=\"hf\", basis=custom_631g_basis, scheme=\"huckel\")\n",
    "plot_mat_comp(ground_truth_fock_example, pred_fock_example, title=\"Fock matrix prediction Basic NN\", vmax=0.5)\n",
    "plot_mat_comp(ground_truth_fock_example, minao_guess.fock().numpy, title=\"Fock matrix prediction MINAO\", vmax=0.5)\n",
    "plot_mat_comp(ground_truth_fock_example, hueckel_guess.fock().numpy, title=\"Fock matrix prediction Hückel\", vmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sim\n",
    "minao_res = calculate(test_mol, method=\"dft\", functional=\"b3lypg\", basis=custom_631g_basis, guess=\"minao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "huckel_res = calculate(test_mol, method=\"dft\", functional=\"b3lypg\", basis=custom_631g_basis, guess=\"huckel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_res = perform_calculation(test_data[rand_test_sample][3], pred_density_example, method=\"dft\", functional=\"b3lypg\", basis_set=custom_631g_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minao_res.native.cycles)\n",
    "print(huckel_res.native.cycles)\n",
    "print(nn_res[\"cycles\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scf_guess_1_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
