\chapter{Background}
\label{sec:background}
This chapter provides an overview of the theoretical background of the methods used in this thesis. While the focus of this thesis is the application of machine learning methods in the quantum chemistry context, a basic introduction to compuatational quantum chemistry methods, namely self consistent field (SCF) methods, is provided. 

\section{Self Consistent Field (SCF) Theory}
\label{sec:background_scf}
Quantum chemistry has its roots far before the advent of the computer age. Based on the original theories on quantum mechanics formulated by Schrödinger and Heisenberg, the interest in the accurate description of matter via this new theory was sparked. After the introduction of the wave function by Schrödinger almost century ago Max Born's statistical interpretation enabled a direct calculation of the electrons density. \parencite{ref:schroedinger_1926undulatory} Already a year later Hartree coined a self consistent method to solve the many-electron problem utilizing a mean-field approach. Slater and Fock independently adapted the method by adding the exchange term and consistency with the Pauli exclusion principle. This method was later named Hartree-Fock (HF) method. \parencite{ref:Hartree_1928,ref:slater1930note,ref:fock1930naherungsmethode}. From that point on many advancements have been made in this field. Most prominently density functional therory (DFT), coupled cluster methods (CC), and perturbation theory (MP2) have been developed. Yet the theory behind the HF method is still the basis for many of these methods.

The following introductry overview of the Hartree-Fock method is largely based on the book by Szabo and Ostlund \parencite{ref:szabo_ostlund}. 

\subsection{Ideas behind the Hartree-Fock method}
\label{subsec:background_hf}
The Born Oppenheimer approximations allows for a seperate treatment of the nuclear and electronic problem of a system. This is motivated by the vastly different masses and hence time-scales of nuclei and electron movement. The total wavefunction of a system may be writen as a product state of electronic and nuclear wavefunction (using the convention of small letters for electrons and capital letters for nuclei coordinates):
\begin{equation}
    \Psi_{\text{tot}}(\mathbf{r}_n, \mathbf{R}_m) = \Psi_{\text{elec}}(\mathbf{r}_n; \mathbf{R}_m) \Psi_{\text{nuc}}(\mathbf{R}_m)
\end{equation}
Given our approximation, the total wavefunction can be derived rather easily from the electronic wavefunction via an effective potential for the nuclear motion, given by a solved electronic wavefunction. However, we will focus on the prerequisit of the electronic wavefunction and hence drop the subscript from now on. It depends parametically on the nuclear coordinates and is the solution to the time independent Schrödinger equation:
\begin{equation}
    H \Psi(\mathbf{r}_n; \mathbf{R}_m) = E(\mathbf{R}_m) \Psi(\mathbf{r}_n; \mathbf{R}_m)
\end{equation}
With the electronic energy $E$ being a functional of the electronic wavefunction which will be minimized under ceratin constraints as we'll see later. 
The Hamiltonian operator $H$ reads: 
\begin{equation}
    H = T + V_{\text{ne}} + V_{\text{ee}} = -\frac{1}{2} \sum_{i=1}^N \nabla_i^2 - \sum_{i=1}^N \sum_{A=1}^M \frac{Z_A}{|\mathbf{r}_i - \mathbf{R}_A|} + \sum_{i<j}^N \frac{1}{|\mathbf{r}_i - \mathbf{r}_j|}
\end{equation}
for $N$ electrons and $M$ nuclei in atomic units. Note that we do not include kinetic or repulsion terms for the nuclei as we are only considering the electronic problem. The first term is the kinetic energy operator, the second term describes the interaction of the electrons with the nuclei and the last term describes the electron-electron interaction.\\

Given the Fermionic problem at hand we have to take antisymmetrization into account. Mathematically this can be achieved by writing the wavefunction using a determinant which ensures parity change under exchange of two rows\footnote{Furthermore, if two electrons occupy the same orbital the determinant will vanish}. For $N$ electrons this can be written as:
\begin{equation}
    \Psi(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_N) = \frac{1}{\sqrt{N!}}
    \begin{vmatrix}
    \chi_1(\mathbf{x}_1) & \chi_2(\mathbf{x}_1) & \cdots & \chi_N(\mathbf{x}_1) \\
    \chi_1(\mathbf{x}_2) & \chi_2(\mathbf{x}_2) & \cdots & \chi_N(\mathbf{x}_2) \\
    \vdots & \vdots & \ddots & \vdots \\
    \chi_1(\mathbf{x}_N) & \chi_2(\mathbf{x}_N) & \cdots & \chi_N(\mathbf{x}_N)
    \end{vmatrix}
\end{equation}
To write down this so called Slater determinant we have introduced the notation $\mathbf{x}_i = (\mathbf{r}_i, \sigma_i)$ with $\sigma_i$ being the spin of electron $i$. The functions $\chi_i$ are called spin orbitals and are a product of spatial and spin functions. 
\begin{equation}
    \label{eq:spin_orbital_expansion}
    \chi_i(\mathbf{x}) = \sum_{\nu} C_{\nu i} \chi_\nu(\mathbf{x}) = \sum_{\nu} C_{\nu i} \phi_\nu(\mathbf{r}) \sigma(\sigma) \text{ with } \bra{\chi_i}\ket{\chi_j} = \delta_{ij}
\end{equation}
Using this expansion we reduce the problem to the determination of the coefficients $C_{\nu i}$ for a given set of orthogonal basis functions $\phi_\nu(\mathbf{r})$. For a complete set of basis functions this expansion is exact. However, in practice we have to limit the number of basis functions and hence the size of our Slater determinant to a computationally feasible size. For the subsequent considerations we introduce the shorthand ket for a slater determinant $\ket{\Psi} = \ket{\chi_1, \chi_2, \ldots, \chi_N}$ or $\ket{\Psi} = \ket{1, 2, \ldots, N}$ for the sake of brevity.

%Energy functional
A slater determinants is one simple way of describing the state of a system as a linear combination of basis functions. From that we can derive the energy of the given systems state $E$ using: 
\begin{equation}
    \label{eq:elec_energy}
    E = \bra{\Psi} H \ket{\Psi}
\end{equation}
For our considerations we will be interested in the ground state of the system. This means we need to find the minimum of our energy functional $E[\Psi]$ and it's corresponding slater determinant $\ket{\Psi}$ which marks our approximation to the ground state wavefunction. This is done via the variational principle which yields an eigenvalue problem: 
\begin{equation}
    \label{eq:hf_eigenval_equation}
    F \ket{\Psi_i} = \varepsilon_i \ket{\Psi_i}
\end{equation}
called the Hartree-Fock (HF) equations. Here $\varepsilon_i$ corresponds to the energy of the $i$-th spin-orbital $\ket{\Psi_i}$. The operator $F$ is called the Fock operator and is defined as an effective one electron operator acting on electron coordinate $i$:
\begin{equation}
    F(i) = 
    \underbrace{
        -\frac{1}{2} \nabla^2 
        - \sum_{A=1}^M \frac{Z_A}{|\mathbf{r} - \mathbf{R}_A|}
    }_{\text{core Hamiltonian } h(i)}
    + 
    \underbrace{
        \sum_{j\neq i} J_j(i) - K_j(i)
    }_{\text{HF potential }v^{HF}(i)}
\end{equation}
While the core Hamiltonian $h(i)$ contains the well-known kinetic and nuclear attraction terms, the Hartree-Fock potential $v^{HF}(i)$ condenses all electron-electron interaction into a mean-field effect on electron $i$ using the Coulomb and exchange terms:
\begin{subequations}
\begin{align}
    J_j(i)\chi_i(\mathbf{x}_1) &= \left[ \int d\mathbf{x}_2\, \frac{|\chi_j(\mathbf{x}_2)|^2}{r_{12}} \right] \chi_i(\mathbf{x}_1) \\
    K_j(i)\chi_i(\mathbf{x}_1) &= \left[ \int d\mathbf{x}_2\, \frac{\chi_j^*(\mathbf{x}_2)\chi_i(\mathbf{x}_2)}{r_{12}} \right] \chi_j(\mathbf{x}_1)
\end{align}
\end{subequations}
Here, $J_j(i)$ is the Coulomb operator, representing the classical electrostatic repulsion, and $K_j(i)$ is the exchange operator, arising from the antisymmetry of the wavefunction.

While \autoref{eq:hf_eigenval_equation} seems like an ordinary eigenvalue problem, the $\chi$ terms in $J$ and $K$ depend on our slater determinant wavefunction $\ket{\Psi}$. Thus to get the ground state wavefunction, we need the corresponding Fock operator $F$ which in turn depends on the ground state wavefunction. 

%DONE

\subsection{Matrix formulation of the Hartree-Fock equations}
\label{subsec:background_hf_computational}
To solve the self-dependence of the Hartree-Fock equations, we need to iteratively update our wavefunction until convergence is reached. To achieve this we first need to express our formal pseudo eigenvalue problem in a way that can be solved numerically. Under the premis that both spin up ($\uparrow$) and spin down ($\downarrow$) electrons have the same spatial distribution -- we call this the restricted HF -- we can write the HF-equations for electron coordinate 1 as:
\begin{equation}
    F(\mathbf{x}_1) \chi_i(\mathbf{x}_1) = \varepsilon_i \chi_i(\mathbf{x}_1) \equiv F(\mathbf{x}_1) \psi_i(\mathbf{r}_1) \sigma_i(\sigma_1) = \varepsilon_i \psi_i(\mathbf{r}_1) \sigma_i(\sigma_1)
\end{equation}
With the spins integrated out we obtain the HF-equations with spatial orbitals: 
\begin{equation}
    \label{eq:hf_eigenval_equation_spatial}
    F(\mathbf{r}_1) \psi_i(\mathbf{r}_1) = \varepsilon_i \psi_i(\mathbf{r}_1)
\end{equation}

which differs from \autoref{eq:hf_eigenval_equation} in the fact that we have integrated out the spin degrees of freedom and thus need to sum over half the electrons (i.e. $\uparrow$) and multiply by two. Therefore $F$ writes:
\begin{equation}
    \label{eq:fock_operator_spatial}
    F(\mathbf{r}_1) = h(\mathbf{r}_1) + 2 \sum_{j\neq i}^{\nicefrac{N}{2}} \left( J_j(\mathbf{r}_1) - K_j(\mathbf{r}_1) \right)
\end{equation}

Finally, we need to represent the spatial orbitals in a finite computer readable way. While the spin orbitals in \autoref{eq:spin_orbital_expansion} are exact for a complete basis set, we will limit ourselvs to a finite set of known basis functions which will approximate the spatial orbitals by linear combination:
\begin{equation}
    \label{eq:psi_approximation}
    \psi_i(\mathbf{r}) \approx \sum_{\nu}^{\nu_\text{max}} C_{\nu i} \phi_\nu(\mathbf{r})
\end{equation}
Approximating the spatial wavefunction using these basis functions (for details see \autoref{subsec:background_hf_basis_sets}) will reduce our problem to the determination of the coefficients $C_{\nu i}$. Finally we insert \autoref{eq:psi_approximation} into \autoref{eq:hf_eigenval_equation_spatial} to obtain the matrix form of the HF equations, the so called Roothaan equations:
\begin{subequations}
    \label{eq:roothaan_equations}
    \begin{align}
        \sum_{\nu}^{\nu_\text{max}} C_{\nu i} \int d\mathbf{r_1} \phi_\mu^*(\mathbf{r_1}) F(\mathbf{r_1}) \phi_\nu^*(\mathbf{r_1})&= \varepsilon_i \sum_{\nu}^{\nu_\text{max}} C_{\nu i} \int d\mathbf{r_1} \phi_\mu^*(\mathbf{r_1})\phi_\nu^*(\mathbf{r_1}) \\
        \Rightarrow \mathbf{F(C)C} &= \mathbf{SC} \boldsymbol{\varepsilon} \label{eq:roothaan_equations_matrix}\\
    \end{align}
\end{subequations}
Where we identify the Fock matrix $\mathbf{F}$, the overlap matrix $\mathbf{S}$, the coefficient matrix $\mathbf{C}$ and the diagonal eigenvalue matrix $\boldsymbol{\varepsilon}$ with elements: 
\begin{subequations}
    \label{eq:roothaan_matrices}
    \begin{align}
        F_{\mu \nu} &= \int d\mathbf{r_1} \phi_\mu^*(\mathbf{r_1}) F(\mathbf{r_1}) \phi_\nu^*(\mathbf{r_1}) \label{eq:roothaan_mat_F}\\
        S_{\mu \nu} &= \int d\mathbf{r_1} \phi_\mu^*(\mathbf{r_1}) \phi_\nu^*(\mathbf{r_1}) \\
        C_{\mu i} &= C_{\nu i} \text{ (coefficients of the } i\text{-th spin orbital)}\\
        \varepsilon_{ij} &= \varepsilon_i \delta_{ij} \text{ (diagonal matrix with orbital energies)}
    \end{align}
\end{subequations}
Ultimately, we are interested in the electron density distribution $\rho(\mathbf{r})$ which is given by the sum of the squares of the occupied spin orbitals: 
\begin{equation}
    \rho(\mathbf{r}) = 2 \sum_{i=1}^{N/2} |\psi_i(\mathbf{r})|^2 = 2 \sum_{i=1}^{N/2} \sum_{\mu,\nu}^{\nu_\text{max}} C_{\mu i} C_{\nu i}^* \phi_\mu(\mathbf{r}) \phi_\nu^*(\mathbf{r}) = \sum_{\mu,\nu}^{\nu_\text{max}} P_{\mu \nu} \phi_\mu(\mathbf{r}) \phi_\nu^*(\mathbf{r})
\end{equation}
Here we have used \autoref{eq:psi_approximation} to express the spatial orbitals in terms of the basis functions\footnote{We still need to multiply by two in order to account for spin up and spin down} and defined the density matrix $\mathbf{P}$.\\
As we have seen earlier, the Fock operator $F$ and thus the Fock matrix $\mathbf{F}$ depend on the expansion coefficients $\mathbf{C}$ and thus the Fock matrix also depends on the density matrix $\mathbf{F(P)}$. If we insert \autoref{eq:fock_operator_spatial} into \autoref{eq:roothaan_mat_F} and write out Coulomb and exchange terms we have: 
\begin{align}
        F_{\mu \nu} &= \underbrace{\int d\mathbf{r}_1\, \phi_\mu^*(\mathbf{r}_1)\, h(\mathbf{r}_1)\, \phi_\nu(\mathbf{r}_1) \nonumber}_{H_{\mu\nu}^\text{core}} \\
        &\quad + \sum_{\lambda \sigma} \mathbf{P}_{\lambda \sigma} \Bigg[
            \underbrace{\iint  d\mathbf{r}_1 d\mathbf{r}_2\, \phi_\mu^*(\mathbf{r}_1) \phi_\nu(\mathbf{r}_1) r_{12}^{-1} \phi_\sigma^*(\mathbf{r}_2) \phi_\lambda(\mathbf{r}_2) \nonumber}_{\text{Coulomb-term}} \\
            &\qquad - \frac{1}{2} \underbrace{\iint d\mathbf{r}_1 d\mathbf{r}_2\, \phi_\mu^*(\mathbf{r}_1) \phi_\lambda(\mathbf{r}_1) r_{12}^{-1} \phi_\sigma^*(\mathbf{r}_2) \phi_\nu(\mathbf{r}_2)}_{\text{Exchange-term}}
            \Bigg]
\end{align}
One and two electron contributions are now split into the core Hamiltonian $H_{\mu\nu}^\text{core}$ which is independent of the density matrix and thus stays constant for a set of basis functions, and the Coulomb and exchange terms which depend on the density matrix $\mathbf{P}$. The later terms are often denoted as $G_{\mu\nu}$, the so called two-electron integrals, hence $F_{\mu \nu} = H_{\mu\nu}^\text{core} + G_{\mu\nu}$.\\

\subsection{Self Consistent Field (SCF) Algorithm}
\label{subsec:background_hf_scf}
We now have all ingredients to solve our Matrix equations \autoref{eq:roothaan_equations_matrix} iteratively. The self consistent field (SCF) algorithm is a fixed point iteration method which means that we initially need the atom coordinates $\mathbf{R}_A$ and atomic numbers. Furthermore, we require the number of electrons $N$ and a set of basis functions $\phi_\nu(\mathbf{r})$ to obtain our orbitals.\\
Initially we also calculate the core Hamiltonian $H_{\mu\nu}^\text{core}$ and the overlap matrix $S_{\mu\nu}$ once (they will be reused in every step) and we guess an initial density. The guess of this initial density is crucial and has a big influences on the convergence speed of the algorithm. Then we start the loop: 
\begin{enumerate}[itemsep=0.1em]
    \item Calculate $G_{\mu\nu}$ using the current $\mathbf{P}$.
    \item Build a new $\mathbf{F}$ using the $H_{\mu\nu}^\text{core}$ and $G_{\mu\nu}$.
    \item Solve the generalized eigenvalue problem to obtain a new $\mathbf{C}$ and $\boldsymbol{\varepsilon}$. \footnote{For numerical stability one usually converts to a standard eigenproblem using canonical orthonormalization: diagonalize $\mathbf{S}=\mathbf{U}\,s\,\mathbf{U}^T$, form $\mathbf{X}=\mathbf{U}\,s^{-1/2}$, solve the standard problem $\mathbf{X}^T\mathbf{F}\,\mathbf{X}\,\mathbf{C}'=\mathbf{C}'\,\boldsymbol{\varepsilon}$, and recover $\mathbf{C}=\mathbf{X}\,\mathbf{C}'$.}
    \item Obtain a new density matrix $\mathbf{P}$ from the new $\mathbf{C}$.
    \item Total energy or $\mathbf{P}$ converged? If not, repeat.
\end{enumerate}

Computationally, the calculation of the two-electron integrals $G_{\mu\nu}$ is the most expensive step which scales with the number of basis functions as $\bigO{n^4}$. Given this fact, a small enough basis set which still captures the essence of the physical system should be chosen and the number of iterations shall be kept to a minimum by a good initial guess. Keeping our approximation of the spatial orbitals via \autoref{eq:psi_approximation} in mind, we see that better approximations of the systems wavefunction and energy can be achieved with larger and larger basis sets. Given the drawback of increased computational cost (mostly in step 1 of the SCF algorithm) a reduction of iterations is even more crucial for larger systems and larger basis sets.

\subsection{Derived quantities}
\label{subsec:background_hf_derived_quantities}
Several quantities can be derived from the solution of the Hartree-Fock equations. As eluded to in \autoref{eq:hf_eigenval_equation} the eigenvalues of $F$ are the orbital energies $\varepsilon_i$. This relation is exact if $F$ is a hermitian operator, which only happends on self-consistency of the equation. Our HF-approximation will thus yield an approximation of the orbital energies for a limited number of states (depending on the size of the basis set). The lowest $\nicefrac{n_\text{elec}}{2}$ eigenvalues correspond to the occupied orbitals, while the rest are so called virtual orbitals \footnote{We still assume closed shell systems with equal number of spin up and spin down electrons.}. One might be tempted to simply sum over the occupied orbital energies to obtain the total energy of the system. However, this is leads to a double counting of the energy given by the exchange interaction for electron pairs. Nevertheless, the orbital energies can still be used to estimate ionisation energies in a frozen shell model called Koopmans' theorem \parencite{ref:koopmans1934}. Removing an electron from an occupied orbital $\chi_i$ will lead to an increase in energy of $\varepsilon_i$.\\

The total energy of the system's ground state of our closed shell system can also be derived using $F$ by inserting our Hamiltonian operator into \autoref{eq:elec_energy}:
\begin{subequations}
\begin{align}
    E_\text{HF} &= \bra{\Psi} H \ket{\Psi} = 2\sum_{i=1}^{N/2} \bra{\chi_i} h(i) \ket{\chi_i}
    + \frac{1}{2}\sum_{i=1}^{N/2}\sum_{j=1}^{N/2} \left[ 2 J_j(i) - K_j(i) \right]\\
    E_\text{HF} &= \sum_{i=1}^{N/2}\left[ h(i) + \varepsilon_i\right] \text{  with  } \varepsilon_i = F_i =  h(i) + \sum_{j}^{N/2} \left[ 2 J_j(i) - K_j(i) \right]\\
    E_\text{HF} &= \frac{1}{2} \sum_{\nu, \mu} \mathbf{P}_{\mu \nu} \left[ H_{\mu \nu}^\text{core} + F_{\mu \nu} \right] = \frac{1}{2} \text{Tr} \left( \mathbf{P} \left[ H^\text{core} + F \right] \right)
\end{align}
\end{subequations}
To get the total energy of the system one usually adds the nuclear repulsion energy $E_\text{nuc} = \sum_{A<B} \frac{Z_A Z_B}{|\mathbf{R}_A - \mathbf{R}_B|}$ to the electronic energy $E_\text{HF}$, yielding the total energy of the system.\\

Additionally of interest is the population of electrons on a given atom from which partial charges can be derived. Using the fact that the density matrix represents spatial orbitals in the atom centered basis set, we can interpret $\mathbf{(PS)}_{\mu \mu}$ as the population of electrons on orbital $\mu$. This leads to the partial charge for an atom $A$ with on-atom centered basis function indices $\mu$:
\begin{equation}
    \
    q_A = Z_A - \sum_{\mu \in A} \mathbf{(PS)}_{\mu \mu}
\end{equation}
The approach to population and charge analysis refers to the so called Mulliken population analysis \parencite{ref:mulliken1955electronic}. 
\subsection{Basis sets}
\label{subsec:background_hf_basis_sets}
For computational treatment our abstract basis functions $\phi_\nu(\mathbf{r})$ need to manifest in a concrete form. 
Motivated by the analytical solution of the Hydrogen atom one can introduce the so called Slater-type orbitals (STOs) using an exponential radial term and spherical harmonics\footnote{for sake of clarity the spherical harmonics term is written with $\Omega$ instead of the to not confuse the functionally dependent $\phi$ with the basis function}: 
\begin{equation}
    \label{eq:slater_orbital}
    \phi_{n, l, m}^{\text{STO}}(r, \Omega, \zeta) = N Y_{l,m}(\Omega) r^{n-1} e^{\zeta r}
\end{equation} 
Computationally, the integrals which occur by using linear combinations of STOs are expensive to calculate. \\

\textbf{Gaussian-Type Orbitals (GTOs)}\\
Fortunately, a very good approximation of STOs can be achieved by combining several Gaussian-type orbitals (GTOs). This combination, called a contraction of GTOs (usually refered to as CGF), only differs in the changed exponential term from the STOs. The GTOs are defined as:
\begin{equation}
    \label{eq:gaussian_orbital}
    \phi_{n, l, m}^{\text{GTO}}(r, \Omega, \zeta) = N Y_{l,m}(\Omega) r^{n-1} e^{-\zeta r^2}
\end{equation}
With each STO modelled by a CGF as: 
\begin{equation}
    \phi_{n, l, m}^{\text{CGF}}(r, \Omega) = \sum_{i=1}^N c_i \phi_{n, l, m}^{\text{GTO}_i}(r, \Omega, \zeta_i)
\end{equation}
The contraction coefficients $c_i$ and the exponents $\zeta_i$ are chosen such that the CGF of a STO-nG basis set approximates the STOs as closely as possible. Common STO-nG basis sets include STO-3G, STO-6-31G or STO-6-31G(2df,p). \\
The nomencalture of these Pople type basis sets \parencite{ref:pople_basis} denotes the number of GTOs used in the contraction. While STO-3G uses three GTOs for each orbital, STO-6-31G uses six GTOs for the inner shell and two functions with three and one GTO respectively for the outer shell. Basis sets using more then one contracted function (31 in 6-31G) are so called double-zeta basis sets; in this particular case a split-valence double zeta basis set because the core orbitals (6 in 6-31G) are modeled with only one contraction. The notation in parentheses denotes additional functions, e.g. STO-6-31G(2df,p) uses two additional d-functions and one f-functions on heavy atoms (\ch{C}, \ch{O}, \ch{N} \& \ch{F}). \\

\textbf{Segmented Contraction}\\
Generally the GTOs used in the contraction of Pople type basis sets are not reused and thus of the segmented contraction type. In contrast, general contraction type basis sets (such as cc-pVXZ \parencite{ref:cc-pVXZ}) reuse some or all primitives in multiple contractions. The later can be converted to a computationally more efficient segmented form which retains the initial accuracy. One such modern segmented basis family optimized for density functional theory are the pcseg-n basis sets. \parencite{ref:Jensen2014pcs}\\

\textbf{Accuracy \& Hatree Limit}\\
Expanding the spatial orbitals using basis functions introduces an error in the electron density distribution and subsequently the converged Energy $E_{HF}$. Given the limitation of a longer runtime--scaling with $\bigO{N^4}$ in the number of basis functions--the accuracy can be refined using a larger and more complete basis set. The so called Hartree limit constitutes the lowest energy asymptotically (theoretically) attainable by any HF-calculation. It can be estimated by the shrinking differences of energies given larger basis-sets. \parencite{ref:Jensen2005hf} Yet, it still lacks so called correlation energy of electrons and thus is makes bonds appear weaker. We will discuss methods which build or improve on Hartree Fock next. 

\subsection{Post-Hartree-Fock Methods}
\label{subsec:background_post_hf}
\TODO{Correlation energy (ref to Accuracy and Hartree Limit in Basis sets? )}
\TODO{MP2 correction}
\subsection{Density Functional Theory (DFT)}
\label{subsec:background_dft}
Density funcitonal theory (DFT) takes an alternative approach to the many-electron problem. It uses a system of non-interacting electrons to approximate the actual interacting electron system. The formulation based on the Hohenberg-Kohn theorems \parencite{ref:hohenberg_kohn1964} states that the ground state energy of a many-electron system is a functional of the electron density $\rho(\mathbf{r})$. Contrary to HF-theory this functional $G[n] = T[n] + E_{\text{ex + corr}}[n]$ encompasses kinetic energy as well as both exchange and correlation energy. \parencite{ref:kohn_sham_1965}\\
While the exact functional cannot be attained, with the expection of free-electron gas, functionals can be constructed via fitting methods to experimental data or higher level methods. Given the functional one solves for the atomic orbitals in an analogous way by minimizing the energy under the constraint of orthogonal orbitals in an iterarative self-consistent way. In practice one usually combines multiple different sources such as fittet functionals, corrections and exact exchange contributions from HF into one functional form. Coefficients for the linear combinations are fittet and can often be altered in quantum physics packages. 
Common choices of DFT functionals are grouped by level of accuracy on Jacob's Ladder include:

\begin{itemize}
    \item \textbf{LDA (Local Density Approximation)}\\
    Assumes that the exchange-correlation energy depends only on the local electron density, as in a uniform electron gas\\
    \textit{Example:} SVWN (Slater exchange + VWN correlation) \parencite{ref:slater1951, ref:vwn1980}

    \item \textbf{GGA (Generalized Gradient Approximation)}\\
    Incorporates both the local density and its gradient\\
    \textit{Example:} PBE (Perdew-Burke-Ernzerhof) \parencite{ref:perdew1996}

    \item \textbf{Meta-GGA}\\
    Adds kinetic energy density or Laplacian of the density\\
    \textit{Example:} SCAN (Strongly Constrained and Appropriately Normed) \parencite{ref:scan2015}

    \item \textbf{Hybrid-GGA}\\
    Mixes exact (Hartree-Fock) exchange with GGA exchange\\
    \textit{Example:} B3LYP (Becke3 + LYP correlation) \parencite{ref:lee_yang_parr_1988, ref:becke_1993}

    \item \textbf{Double Hybrids}\\
    Adds second-order perturbation theory (like MP2) to hybrid functionals; uses occupied and unoccupied orbitals.\\
    \textit{Example:} B2PLYP (Becke2 + LYP + MP2 correction) \parencite{ref:grimme2006}
\end{itemize}



\section{Machine Learning}
\label{sec:background_ml}
%! Intor to ML & Statistical Learning. 
\subsection{Cost Functions}
\label{subsec:background_cost_function}
\TODO{also discuss f-score!!!}

\section{QM9 dataset \parencite{ref:data_qm9}}
\label{sec:qm9}
During selection of a dataset for training two practical considerations dominate. 
\begin{enumerate}
    \item Cost per sample: Time savings through faster convergence are especially relevant for larger systems where the number of SCF iterations are and especially the number of integrals to be calculated are large. Stated differently, it is of very little interest to optimize guessing methods for small systems which converge nearly instantly on conventional hardware. 
    \item Fixed I/O size: Most ML models are constraint to a constant input and output size. 
\end{enumerate}
The QM9 dataset \parencite{ref:article1_qm9,ref:article2_qm9} ticks both of these two boxes. It offers a variety of molecules from as little as 3 constituent atoms up to 29 atoms. Additionally, there are large enough chunks of constitutional isomers to train models on these subsets of same sized matrices. The distribution of molecules by atom count with the predominant constitutional isomers is shown in \autoref{fig:method_qm9_overview}.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../fig/qm9_general/qm9_overview_stacked_bar.pdf}
    \caption[QM9 dataset overview]{Overview of the QM9 dataset. The dataset contains 134k molecules with up to nine heavy - \ch{C} \ch{O} \ch{N} \ch{F} - atoms. Large groups of constitutional isomers are present (largest depicted in red). The properties are calculated using DFT with the B3LYP functional and the 6-31G(2df,p) basis set.}
    \label{fig:method_qm9_overview}
\end{figure}
